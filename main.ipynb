{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/Shareddrives/FP/FP/ML_ImageCaptioning/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up conda\n",
        "\n",
        "This part is crucial as google colab does not have conda by default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "%env PYTHONPATH =\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
        "!./Miniconda3-py38_4.12.0-Linux-x86_64.sh -b -f -p /usr/local\n",
        "#!conda update conda\n",
        "!conda update -n base -c defaults conda\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.8/site-packages')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "#%%shell\n",
        "!conda create -n ICwFR python=3.9\n",
        "!conda activate ICwFR\n",
        "!conda --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installing requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision  --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip  install -r requirements.txt\n",
        "!python -m spacy download en\n",
        "!python grit/models/ops/setup.py build develop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inputting images and faces into the database\n",
        "Note: Please change the path into your own image path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "!python cap.py --face_input \"/content/drive/Shareddrives/FP/FP/Captioning/images/0001.jpg\" --name_input \"Owen\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Caption Output\n",
        "\n",
        "\n",
        "| Arguments | Purpose |  \n",
        "| -- | -- |\n",
        "| `--image_input` | the directory path to the input image |\n",
        "| `--no_facial_recognition` | output without face recognition |\n",
        "| `--tts_path` | the directory path to the tts output |\n",
        "| `--output_path` | the directory path to the .txt caption |\n",
        "| `--exp_checkpoint` | the file path to the pre-trained weights |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "!python cap.py --image_input \"/content/drive/Shareddrives/FP/FP/Captioning/images/0003.jpg\" --exp_checkpoint \"/content/drive/Shareddrives/FP/FP/Captioning/grit/grit_checkpoint_4ds.pth\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
